.. This file is automatically generated. Do not edit this file directly.

Google BigQuery Python Samples
===============================================================================

This directory contains samples for Google BigQuery. `Google BigQuery`_ is Google's fully managed, petabyte scale, low cost analytics data warehouse. BigQuery is NoOps—there is no infrastructure to manage and you don't need a database administrator—so you can focus on analyzing data to find meaningful insights, use familiar SQL, and take advantage of our pay-as-you-go model.




.. _Google BigQuery: https://cloud.google.com/bigquery/docs 

Setup
-------------------------------------------------------------------------------


Authentication
++++++++++++++

Authentication is typically done through `Application Default Credentials`_,
which means you do not have to change the code to authenticate as long as
your environment has credentials. You have a few options for setting up
authentication:

#. When running locally, use the `Google Cloud SDK`_

    .. code-block:: bash

        gcloud auth application-default login


#. When running on App Engine or Compute Engine, credentials are already
   set-up. However, you may need to configure your Compute Engine instance
   with `additional scopes`_.

#. You can create a `Service Account key file`_. This file can be used to
   authenticate to Google Cloud Platform services from any environment. To use
   the file, set the ``GOOGLE_APPLICATION_CREDENTIALS`` environment variable to
   the path to the key file, for example:

    .. code-block:: bash

        export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service_account.json

.. _Application Default Credentials: https://cloud.google.com/docs/authentication#getting_credentials_for_server-centric_flow
.. _additional scopes: https://cloud.google.com/compute/docs/authentication#using
.. _Service Account key file: https://developers.google.com/identity/protocols/OAuth2ServiceAccount#creatinganaccount

Install Dependencies
++++++++++++++++++++

#. Install `pip`_ and `virtualenv`_ if you do not already have them.

#. Create a virtualenv. Samples are compatible with Python 2.7 and 3.4+.

    .. code-block:: bash

        $ virtualenv env
        $ source env/bin/activate

#. Install the dependencies needed to run the samples.

    .. code-block:: bash

        $ pip install -r requirements.txt

.. _pip: https://pip.pypa.io/
.. _virtualenv: https://virtualenv.pypa.io/

Samples
-------------------------------------------------------------------------------

Simple Application
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python simple_app.py


Quickstart
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python quickstart.py


Query
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python query.py

    usage: query.py [-h] [--use_standard_sql]
                [--destination_table DESTINATION_TABLE]
                query
    
    Command-line application to perform queries in BigQuery.
    
    For more information, see the README.rst.
    
    Example invocation:
        $ python query.py '#standardSQL
              SELECT corpus
              FROM `bigquery-public-data.samples.shakespeare`
              GROUP BY corpus
              ORDER BY corpus'
    
    positional arguments:
      query                 BigQuery SQL Query.
    
    optional arguments:
      -h, --help            show this help message and exit
      --use_standard_sql    Use standard SQL syntax.
      --destination_table DESTINATION_TABLE
                            Destination table to use for results. Example:
                            my_dataset.my_table


Parameterized Query
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python query_params.py

    usage: query_params.py [-h] {named,positional,array,timestamp,struct} ...
    
    Command-line app to perform queries with parameters in BigQuery.
    
    For more information, see the README.rst.
    
    Example invocation:
        $ python query_params.py named 'romeoandjuliet' 100
        $ python query_params.py positional 'romeoandjuliet' 100
    
    positional arguments:
      {named,positional,array,timestamp,struct}
                            samples
        named               Run a query with named parameters.
        positional          Run a query with positional parameters.
        array               Run a query with an array parameter.
        timestamp           Run a query with a timestamp parameter.
        struct              Run a query with a struct parameter.
    
    optional arguments:
      -h, --help            show this help message and exit


Snippets
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python snippets.py

    usage: snippets.py [-h] [--project PROJECT]
                       {list-projects,list-datasets,list-tables,create-table,list-rows,copy-table,delete-table}
                       ...
    
    Samples that demonstrate basic operations in the BigQuery API.
    
    For more information, see the README.rst.
    
    Example invocation:
        $ python snippets.py list-datasets
    
    The dataset and table should already exist.
    
    positional arguments:
      {list-projects,list-datasets,list-tables,create-table,list-rows,copy-table,delete-table}
        list-projects
        list-datasets       Lists all datasets in a given project. If no project
                            is specified, then the currently active project is
                            used.
        list-datasets       Lists all datasets in a given project. If no project
                            is specified, then the currently active project is
                            used.
        list-tables         Lists all of the tables in a given dataset. If no
                            project is specified, then the currently active
                            project is used.
        create-table        Creates a simple table in the given dataset. If no
                            project is specified, then the currently active
                            project is used.
        list-rows           Prints rows in the given table. Will print 25 rows at
                            most for brevity as tables can contain large amounts
                            of rows. If no project is specified, then the
                            currently active project is used.
        copy-table          Copies a table. If no project is specified, then the
                            currently active project is used.
        delete-table        Deletes a table in a given dataset. If no project is
                            specified, then the currently active project is used.
    
    optional arguments:
      -h, --help            show this help message and exit
      --project PROJECT


Load data from a file
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python load_data_from_file.py

    usage: load_data_from_file.py [-h] dataset_id table_id source_file_name
    
    Loads data into BigQuery from a local file.
    
    For more information, see the README.rst.
    
    Example invocation:
        $ python load_data_from_file.py example_dataset example_table \
            example-data.csv
    
    The dataset and table should already exist.
    
    positional arguments:
      dataset_id
      table_id
      source_file_name  Path to a .csv file to upload.
    
    optional arguments:
      -h, --help        show this help message and exit


Load data from Cloud Storage
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python load_data_from_gcs.py

    usage: load_data_from_gcs.py [-h] dataset_id table_id source
    
    Loads data into BigQuery from an object in Google Cloud Storage.
    
    For more information, see the README.rst.
    
    Example invocation:
        $ python load_data_from_gcs.py example_dataset example_table \
            gs://example-bucket/example-data.csv
    
    The dataset and table should already exist.
    
    positional arguments:
      dataset_id
      table_id
      source      The Google Cloud Storage object to load. Must be in the format
                  gs://bucket_name/object_name
    
    optional arguments:
      -h, --help  show this help message and exit


Load streaming data
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python stream_data.py

    usage: stream_data.py [-h] dataset_id table_id json_data
    
    Loads a single row of data directly into BigQuery.
    
    For more information, see the README.rst.
    
    Example invocation:
        $ python stream_data.py example_dataset example_table \
            '["Gandalf", 2000]'
    
    The dataset and table should already exist.
    
    positional arguments:
      dataset_id
      table_id
      json_data   The row to load into BigQuery as an array in JSON format.
    
    optional arguments:
      -h, --help  show this help message and exit


Export data to Cloud Storage
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python export_data_to_gcs.py

    usage: export_data_to_gcs.py [-h] dataset_id table_id destination
    
    Exports data from BigQuery to an object in Google Cloud Storage.
    
    For more information, see the README.rst.
    
    Example invocation:
        $ python export_data_to_gcs.py example_dataset example_table \
            gs://example-bucket/example-data.csv
    
    The dataset and table should already exist.
    
    positional arguments:
      dataset_id
      table_id
      destination  The destination Google Cloud Storage object. Must be in the
                   format gs://bucket_name/object_name
    
    optional arguments:
      -h, --help   show this help message and exit




The client library
-------------------------------------------------------------------------------

This sample uses the `Google Cloud Client Library for Python`_.
You can read the documentation for more details on API usage and use GitHub
to `browse the source`_ and  `report issues`_.

.. _Google Cloud Client Library for Python:
    https://googlecloudplatform.github.io/google-cloud-python/
.. _browse the source:
    https://github.com/GoogleCloudPlatform/google-cloud-python
.. _report issues:
    https://github.com/GoogleCloudPlatform/google-cloud-python/issues


.. _Google Cloud SDK: https://cloud.google.com/sdk/